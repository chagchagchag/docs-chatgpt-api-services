{"/":{"title":"Introduction","data":{"":"ChatGPT, FastAPI, python 을 이용한 여러가지 자동화 도구를 만들어본 과정들을 기록하는 페이지입니다.ChatGPT 가 아직은 태동기이긴 하지만, 어떤 식으로 질문을 던지고 이런 것들에 대한 연습이 된다면, 필요한 부분 들에서 어느 정도의 생산성을 개발팀에 제공해줄 수 있을 것이라고 추측하는 사람 중의 1인 입니다!!최근 NVDA 의 전력소비량이 크기도 하고, GPU가 너무 비싸서 여러 스타트업에서 새로운 AI 프로세서를 설계해서 출시하고 있기에 조금 더 경제적인 AI 프로세서가 나온다면, 스타트업에서도 더 좋은 생성형 AI 서비스가 나오지 않을까 싶습니다.물론 저는 서비스 개발 쪽에 가까운 사람이기에 AI 에 대한 입장은 사용자 측이기에 별로 관심을 안가져도 되지만, NVDA 에 대항할 만한 더 싸고 경제적인 프로세서가 나와서 대기업 뿐만 아니라 스타트업에서도 GPT와 비슷한 수준의 서비스가 나오기를 고대하고 있습니다."}},"/installation-and-setting":{"title":"Installation and Setting","data":{"installation-settings#Installation, Settings":""}},"/installation-and-setting/python-install":{"title":"Python Install","data":{"python-설치#Python 설치":"파이썬을 설치하는 방법은 아래의 3가지 방법이 있습니다.\npython.org 를 방문해서 다운로드 후 설치\nanaconda 에서 제공하는 SDK 설치\nminiconda 에서 제공하는 SDK 설치\npython.org 에서는 zip 파일을 다운받을수도 있고 installer를 받을수도 있고 매우 다양한 방법이 제공됩니다. 최근에는 docker 기반으로 서비스를 배포하는 경우가 많기에 굳이 python.org 에서 python 을 다운로드 받아서 설치하는 경우가 많지는 않겠지만, 경량화된 버전의 공식 python 을 설치하려면 python.org 에서 다운로드 받아서 설치합니다.anaconda 에서는 부가적으로 설치되는 수학 라이브러리들이 많습니다. 용량도 꽤 크기에 개인적인 용도로 사용하고 싶지는 않았습니다.이번 문서에서 사용하는 python 은 miniconda 에서 제공하는 경량화된 버전의 python 을 사용합니다.","miniconda-방문--python-설치#miniconda 방문 & python 설치":"https://docs.anaconda.com/free/miniconda/index.html 에 방문합니다. 그리고 좌측의 Miniconda → Installing Miniconda 를 클릭합니다.\n원하는 버전을 선택한 후 다운로드합니다.이 다음부터의 설치는 설치될 경로를 제외하고 모두 기본옵션으로 설치해줬습니다.","20240421#2024.04.21":"현재 시점인 2024.04.21 에는 이미 python 을 제가 설치를 해뒀습니다. python.org 를 통해서 설치했던 것으로 보이고 노트북 처음 설치했을때 크롤링을 하려고 했던 건지는 모르겠지만 설치했던 듯 합니다.","virtualenv#virtualenv":"참고\nvirtualenv\ninstallation\nvirtualenv 는 파이썬의 실행환경을 가상환경에서 실행할 수 있도록 도와주는 환경입니다. 어떤 프로젝트의 의존성이 전역적으로 설치되면 다른 프로젝트의 의존성과 충돌되기도 합니다. python 에서는 이런 문제를 해결하기 위해 virtualenv 를 통해 관리가 가능합니다. Nodejs 에서도 이런 가상환경이 있는 것으로 알고있지만 기억은 아나네요!!(ㅠㅠ)","설치#설치":"python -m pip install --user virtualenv\n이외에 다른 방법으로 설치하려면 installation 을 참고해주시면 됩니다. 위의 설치 방법은 virtualenv 를 전역적으로 설치하기 위한 방법입니다.위의 과정을 거친 후에도 윈도우에서는 조금 귀찮은 설정을 하나 더 해주셔야 합니다.설치과정을 보면 아래와 같은 디렉터리가 나타나는데요.\n위에서 나타난 경로 들 중에서 아래의 디렉터리로 이동해봅니다.\nC:\\Users\\user\\AppData\\Roaming\\Python\\Python312\n방문해보면 아래와 같은 디렉터리가 나타나는데요. 그 중 Scripts 디렉터리로 이동합니다.\n그리고 이동한 곳에는 virtualenv 가 존재한다는 사실을 확인 가능합니다.이 virtualenv 를 환경변수의 PATH 에 추가해주면 됩니다. 제 경우에는 V:\\000.env\\usr\\local\\bin 라는 곳에 필요한 바이너리들을 모아두고 V:\\000.env\\usr\\local\\bin 을 윈도우 전역 Path 에 등록해두었기 때문에 virtualenv 파일을 V:\\000.env\\usr\\local\\bin 에 복사해두는 것으로 virtualenv 설치를 마무리했습니다.","사용#사용":"","가상환경-생성#가상환경 생성":"$ virtualenv hello","가상환경-진입#가상환경 진입":"$ source Scripts/activate\r\n(hello)","가상환경에서-나오기#가상환경에서 나오기":"$ deactivate\n참고로 아래와 같이 하면 가상환경에서 나오는 것이 불가능햅니다.\n$ source Scripts/deactivate.bat"}},"/open-ai-how-to":{"title":"Open Ai How To","data":{"open-ai#Open AI":"취업 준비중이라 자주 정리하지는 못하지만, 시간이 되는대로 예제들을 추가해나가겠습니다.!!\nOpen AI 란?\n단점(Hallucination, bias, ...)\n간략한 예제들\n번역\n음성인식\n챗봇"}},"/open-ai-how-to/shortcomming-open-ai":{"title":"Shortcomming Open Ai","data":{"openai-의-단점#OpenAI 의 단점":"","대표적인-사례#대표적인 사례":"출처 : 한국일보 - \"세종대왕 맥북 던짐 사건 알려줘\" 물었더니... 챗GPT의 엉뚱답변 '밈'으로 유행중","개인적인-경험#개인적인 경험":"","chatgpt-는-문과적인-데이터는-꽤-좋아하는-것-같고-척척-박사#ChatGPT 는 문과적인 데이터는 꽤 좋아하는 것 같고 척척 박사":"개인적으로는 정보를 요약하거나 종합하는건 정말 기가 막히다고 생각했습니다.\r\n영문 재무제표를 공부할 때 이 항목이 어떻게 구성되고 한국 재무제표 용어는 이렇게 표현되고, 이런 것들을 설명해줍니다.\n어느 정도의 암기와 이해력만 있으면 가능한 것들은 잘 조합해주는 것 같습니다.","코딩-능력은-좀-많이-떨어지고-거짓말을-좀-한다#코딩 능력은 좀 많이 떨어지고, 거짓말을 좀 한다.":"예전에 스프링 시큐리티의 Reactive 버전의 예제를 작성할때 초안을 ChatGPT에게 작성해달라고 하고 고쳐서 쓰려고 했는데 결국은 처음부터 다시 공식문서를 보고 다시 작성했습니다. 아마 직접 공식문서를 보고 코드를 작성했다면 더 빠르게 작업이 됐을 기억이었습니다.StepVerifier 문서를 작성할 때에도 StepVerifier 관련 예제를 작성하기 잠깐 귀찮아져서 초안을 작성해달라고 해서 그 코드를 보고 테스트 코드를 작성해봤는데, 이것 역시 Deprecated 된 코드를 GPT가 작성해줬었습니다.한편으로 최근에 copilot 이라고 해서 자동완성 기능을 GPT가 제공하는데 이 기능은 좋은 듯 해보입니다. ChatGPT는 아직 인간의 사고능력을 직접 생성해낸다기 보다는 특정 패턴에 맞게끔 자동 생성이나 추천을 하는 능력이 좋은 것 같습니다."}},"/open-ai-how-to/translation-service":{"title":"Translation Service","data":{"번역-서비스-예제#번역 서비스 예제":"Open AI 를 조금 더 잘 쓰려면 계속해서 공부하고 원하는 답이 잘 찾아지게끔 질문을 만드는 연습이 필요하지만, 이번 문서에서는 단순한 예제 코드만 남겨보면 아래와 같습니다.","gpt35-엔진-으로-작성해보기#gpt3.5 엔진 으로 작성해보기":"코드는 아래와 같습니다.\nfrom openai import OpenAI\r\nimport os\r\nimport streamlit as st\r\n\r\nkey = os.getenv(\"OPEN_AI_KEY\")\r\nclient = OpenAI(api_key = key)\r\n\r\n\r\nst.title(\"번역하기\")\r\nuser_input = st.text_area(\"여기에 번역을 원하는 글을 적어주세요\", \"\")\r\n\r\nsrc_lang = st.radio(\r\n    \"원본 언어 선택\",\r\n    [\"한국어\", \"영어\"]\r\n)\r\n\r\ntarget_lang = st.radio(\r\n    \"번역 언어 선택\",\r\n    [\"한국어\", \"영어\"]\r\n)\r\n\r\ndef translate(input, src, target):\r\n    todo = f\"\"\"\r\n        src = {src_lang} 으로 쓰여진 아래의 글을 target = {target_lang}으로 번역해주세요.\r\n        \r\n        from: 안녕하세요\r\n        to: Hello\r\n        src: 한국어\r\n        target: 영어\r\n\r\n        from: Nice to Meet You\r\n        to: 반가워요\r\n        src: 영어\r\n        target: 한국어\r\n\r\n        src: {src_lang}\r\n        target: {target_lang}\r\n        from: {input}\r\n        to: \r\n    \"\"\"\r\n\r\n    response = client.completions.create(\r\n        model=\"gpt-3.5-turbo-instruct\",\r\n        prompt=todo,\r\n        max_tokens=200,\r\n        n=1,\r\n        temperature=1\r\n    )\r\n\r\n    return response.choices[0]\r\n\r\n\r\nst.text(f\"{src_lang} -> {target_lang}\")\r\n\r\nflag = st.button(\"번역하기\")\r\n\r\nif(flag):\r\n    response = translate(user_input, src_lang, target_lang)\r\n    print(f\"result = {response}\")\r\n    st.success(f\"번역 결과 : {response.text}\")\n실행해봅니다.\n$ streamlit run chatgpt-translate.py\n출력결과는 아래와 같습니다."}},"/open-ai-how-to/basic-structure":{"title":"Basic Structure","data":{"기본적인-구조#기본적인 구조":"이번 문서에서는 어떤 구조로 예제들을 구성할지를 정리합니다.빠른 시일 내에 배포 관련된 챕터도 따로 예제와 함께 문서로 만들어둘 예정입니다.","예제-서비스-구성#예제 서비스 구성":"예제로 사용할 번역, 요약, 챗봇, 음성인식 등의 서비스들은 모두 아래의 구조로 작성할 예정이며, 이번 챕터에서는 모두 로컬 개발 PC 에서 구동하는 것을 전제로 합니다."}},"/open-ai-how-to/open-ai-start":{"title":"Open Ai Start","data":{"open-ai-시작하기#Open AI 시작하기":"","참고#참고":"openai.com\nopenai.com/docs/introduction\nopenai.com/docs/quickstart?context=python\nStep 2: Set up your API key\nStep 3: Sending your first API request","개발자-문서#개발자 문서":"openai.com 에 접속해서 API → Docs 로 메뉴 이동합니다.\n이동한 Documentaion 페이지에서는 좌측 사이드 바에서 GET STARTED → Quckstart 를 클릭합니다.\n이번 문서에서 작성하는 내용들은 대부분 위의 문서에 나온 내용들을 요약해서 적어봅니다.","가상환경-생성-파이썬-library-세팅#가상환경 생성, 파이썬 library 세팅":"자세한 내용은 Step 1: Setting up Python 을 참고해주세요.\n## 가상환경 생성\r\n$ virtualenv open-ai-start\r\n\r\n## 가상환경 디렉터리로 이동\r\n$ cd open-ai-start/\r\n\r\n## 가상환경 activate\r\n$ source Scripts/activate\r\n(open-ai-start)\r\n\r\n## openai 라이브러리 설치\r\n$ pip install --upgrade openai\nvscode 에서도 가상환경을 설정해줍니다. (저는 python 에디터로 vscode 를 씁니다.)먼저 Ctrl + Shift + P → > interpreter 검색 → Python: Select Interpreter 선택 을 통해서 Interpreter 선택 메뉴로 이동합니다.\n맥북에서는 Cmd + Shift + P 입니다.\n위에서 미리 생성해둔 virtualenv 인 open-ai-start 를 선택합니다.\n만약 이렇게 해도 vscode 터미널에 virtualenv 가 적용이 안된다면 아래와 같이 직접 source ./Scripts/activate 를 실행해주세요.","api-key-생성#api key 생성":"openapi.com 에 회원으로 로그인 합니다. 그리고 마이페이지로 이동합니다. 이동한 페이지에서는 API keys → +Create new secret key 를 선택합니다.\nSecret Key 를 생성하는 데에 필요한 정보들을 입력해줍니다. 그리고 Create secret key 버튼을 클릭합니다.\nSecret Key 를 복사해서 필요한 곳에 저장해둡니다. github 의 Environments 에 변수 등록할수도 있고, 환경변수로 등록할수는 등 여러가지 방법으로 키를 보관해두시면 됩니다. 제 경우에는 서버에 배포할게 아니기 때문에 별도의 하드디스크에 txt 파일을 생성해서 기록해두었습니다.","개발pc-환경변수로-등록#개발PC 환경변수로 등록":"Step 2: Set up your API key 를 참고해주세요.\n예제 문서 작성중에 계속해서 API_KEY 를 노출시킨 코드를 주석처리하는 것은 불편하기에 개발PC에 임시적으로 환경변수로 처리해두었습니다.아래 명령어를 통해 OPEN_AI_KEY 라는 환경변수를 등록합니다.\n$ export OPEN_AI_KEY=[여기에 적어주세요]\n이번에는 등록한 환경변수를 출력해봅니다.\n$ echo ${OPEN_AI_KEY}","completion-api#Completion API":"참고 : https://platform.openai.com/docs/api-reference/completions","model#model":"model 에는 대표적으로 아래와 같은 것들이 있습니다. 자세한 내용은 https://platform.openai.com/docs/models/overview 을 참고해주세요.\nMODEL\tDESCRIPTION\tGPT-4 Turbo and GPT-4\tA set of models that improve on GPT-3.5 and can understand as well as generate natural language or code\tGPT-3.5 Turbo\tA set of models that improve on GPT-3.5 and can understand as well as generate natural language or code\tDALL·E\tA model that can generate and edit images given a natural language prompt\tTTS\tA set of models that can convert text into natural sounding spoken audio\tWhisper\tA model that can convert audio into text\tEmbeddings\tA set of models that can convert text into a numerical form\tModeration\tA fine-tuned model that can detect whether text may be sensitive or unsafe\tGPT base\tA set of models without instruction following that can understand as well as generate natural language or code\tDeprecated","prompt#prompt":"질문을 의미합니다. 이번 문서에서 사용한 예제에서는 아래의 코드를 사용했고, prompt 에는 질문을 의미합니다.\n# ...\r\n\r\nresponse = client.completions.create(\r\n  model=\"gpt-3.5-turbo-instruct\",\r\n  prompt=\"Say this is a test\",\r\n  max_tokens=7,\r\n  temperature=0\r\n)","max_tokens#max_tokens":"출력으로 내보낼 때 한번에 내보낼 응답의 길이를 의미합니다.max_tokens 가 길면 각 응답마다 내보내는 응답의 길이를 길게 내보내고 짧으면 응답마다 내보내는 응답의 길이를 짧게 내보낼 수 있습니다.크게 잡더라도 선택한 open ai 모델 입장에서 더 짧게 생성하는게 맞다 판단할 때는 한번 응답시에 짧게 내보내는 경우도 있습니다. tokens 라는 것은 음절, 단어 등과 같은 인간 기준의 토큰 기준을 의미하는 것이 아닙니다. tokens 는 Open AI 내부적으로 사용되는 tick token 이라는 토크나이저가 있는데, 이 토크나이저가 분류한 token 을 tokens 라고 합니다.","temperature#temperature":"모델을 이용해서 출력을 내보낼 때의 Randomness 를 의미합니다. Randomness 가 낮으면 낮을 수록 같은 응답을 내보낼 확률이 높고, Randomness 가 높으면 높을 수록 다른 응답으로 내보낼 확률이 높아집니다. 즉, Temperature 가 높을 수록 다양한 답변을 내놓을 확률이 높으며 Temperature 가 낮을 수록 매번 같은 응답을 내놓을 확률이 높습니다.","top_p#top_p":"어떤 질문에 대해 응답할 때에는 토큰 단위로 응답을 하는데 이 토큰은 10만개 정도의 토큰 데이터에서 선택을 해서 내보내게 됩니다. 이 토큰 들에는 출현확률을 의미하는 점수들이 매겨져 있는데, 이 점수가 높은 순으로 위에서부터 Top P 만큼을 끊어서 가져오게 됩니다. Top_p 라고 이름이 지어진 이유는 토큰들이 출현할 확률을 의미하는 percent 로 스코어가 매겨져 있어서 top_p 라고 부릅니다. 쉽게 이야기하면 top_p 는 원하는 확률(p) 내의 범위에 존재하는 토큰들을 의미합니다.만약 top_p = 0.5 로 전달받았고, 토큰들은 {0.3, 0.2, 0.1, 0.1, 0.1, 0.1, 0.1} 로 지정되어 있을 때 가장 처음의 {0.3, 0.2} 의 합이 0.5 이기에 {0.3, 0.2} 의 출현확률을 가진 2개의 토큰을 응답으로 내보내게 됩니다.10만개 정도의 토큰들을 저장한 배열을 백터라고 부르는데, 이 토큰 들의 스코어인 percent 를 모두 합치면 1이 됩니다.top_p 를 줄이면 줄일 수록 더 적은 토큰들의 범위 내에서 샘플링을 하게 됩니다.temperature 와 동시에 사용되지는 않습니다.","presense_penalty-frequency_penalty#presense_penalty, frequency_penalty":"어떤 토큰이 반복적으로 나오지 않도록 패널티를 부여하는 것을 의미합니다.\n더 자세한 내용은 생략합니다.","api-문서-찾아보는-법#API 문서 찾아보는 법":"위에서는 OpenAI 의 여러 기능 중에서 Completion 이라는 기능을 사용했습니다. Completion 기능에 대한 명세는 API Reference 에서 찾아볼수 있습니다.위에서 살펴봤던 Quick Start 페이지 상단에는 API reference 라는 메뉴가 있고 좌측 사이드 바의 LEGACY 메뉴를 보면 Completion 이라는 항목이 있습니다. Completion 을 클릭하면 Completion 기능에 대한 명세를 확인할 수 있습니다.","completion-api--첫-번째-예제#Completion API : 첫 번째 예제":"참고자료\nStep 3: Sending your first API request\nCreate completion\nfirst-demo.py\nfrom openai import OpenAI\r\nimport os\r\n\r\nkey = os.getenv(\"OPEN_AI_KEY\")\r\nclient = OpenAI(api_key = key)\r\n\r\nresponse = client.completions.create(\r\n  model=\"gpt-3.5-turbo-instruct\",\r\n  prompt=\"Say this is a test\",\r\n  max_tokens=7,\r\n  temperature=0\r\n)\r\n\r\nprint(f\"response = {response}\")\n출력해보면 아래와 같은 결과가 나타납니다.\n$ python first-demo.py \r\nresponse = Completion(id='cmpl-9GddNSmIbqRwf7prbZNSnrRBoShZu', choices=[CompletionChoice(finish_reason='stop', index=0, logprobs=None, text='\\n\\nThis is a test.')], created=1713752629, model='gpt-3.5-turbo-instruct', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=6, prompt_tokens=5, total_tokens=11))\r\n(open-ai-start) \n위의 코드에서 OpenAI 를 호출하는 부분은 아래와 같았습니다.\n# ...\r\n\r\nresponse = client.completions.create(\r\n  model=\"gpt-3.5-turbo-instruct\",\r\n  prompt=\"Say this is a test\",\r\n  max_tokens=7,\r\n  temperature=0\r\n)","completion-api--두-번째-예제#Completion API : 두 번째 예제":"Completion API 는 아래와 같은 예제로도 쓰일 수 있습니다.second-demo.py\nfrom openai import OpenAI\r\nimport os\r\n\r\nkey = os.getenv(\"OPEN_AI_KEY\")\r\nclient = OpenAI(api_key = key)\r\n\r\nprompt = \"\"\"\r\n마지막 문장이 긍정적이라면 '긍정적인 기사에요' 를, 부정적이라면 '부정적인 기사에요' 를 표시해주세요.\r\n\r\nquery: 삼성중공업, 드디어 흑자전환\r\nsentiment: 긍정적인 기사에요\r\n\r\nquery: 조선업, 달러 강세시 실적에는 조금 부정적인 영향\r\nsentiment: 부정적인 기사에요\r\n\r\nquery: 삼성중공업, 직전 분기 흑자전환했지만, 소폭의 달러강세로 인해...\r\nsentiment: \r\n\"\"\"\r\n\r\nresponse = client.completions.create(\r\n  model=\"gpt-3.5-turbo-instruct\",\r\n  prompt=prompt,\r\n  max_tokens=7,\r\n  temperature=0\r\n)\r\n\r\n# print(f\"response = {response}\")\r\nprint(response.choices[0].text)\n참고로 response['choices'][0]['text'] 와 같이 사용할 경우 아래의 에러를 접하게 됩니다.\nTypeError: 'Completion' object is not subscriptable\n참고 : Open AI TypeError: 'Completion' object is not subscriptable\n출력결과\n$ python second-demo.py \r\n부정적인 기사에\r\n(open-ai-start) \n한국어는 마지막 글자가 잘리는 문제가 있지만, 부정적인 기사 라고 정확하게 표기되는 것을 확인 가능합니다.","completion-api--세-번째-예제#Completion API : 세 번째 예제":"두번째 예제와 비슷한 구조이지만 입력을 받아서 이것의 결과를 출력하는 예제입니다.third-demo.py\nfrom openai import OpenAI\r\nimport os\r\n\r\nkey = os.getenv(\"OPEN_AI_KEY\")\r\nclient = OpenAI(api_key = key)\r\n\r\nprompt = \"\"\"\r\n마지막 문장이 긍정적이라면 '긍정적인 기사에요' 를, 부정적이라면 '부정적인 기사에요' 를 표시해주세요.\r\n\r\nquery: 삼성중공업, 드디어 흑자전환\r\nsentiment: 긍정적인 기사에요\r\n\r\nquery: 조선업, 달러 강세시 실적에는 조금 부정적인 영향\r\nsentiment: 부정적인 기사에요\r\n\r\nquery:  \r\n\"\"\"\r\n\r\nquestion = input(\"질문을 입력해주세요 >> \")\r\n\r\nprompt = prompt + question + \"\\nsentiment: \"\r\n\r\nresponse = client.completions.create(\r\n  model=\"gpt-3.5-turbo-instruct\",\r\n  prompt=prompt,\r\n  max_tokens=7,\r\n  temperature=0\r\n)\r\n\r\n# print(f\"response = {response}\")\r\nprint(response.choices[0].text)\n실행\n$ python third-demo.py \r\n질문을 입력해주세요 >> 9년만의 흑자 순항하는 삼성중공업... 바다위 LNG 공장 히든카드\r\n긍정적인 기사\r\n(open-ai-start)","응답이-깨져-보일때#응답이 깨져 보일때":"로컬 개발 PC에서 테스트 시에 응답이 깨져서 보이거나 한글이 깨져서 보이는 경우가 있습니다. ChatGPT 가 Response 로 전달해주는 값은 dictionary 자료형이 아니라 OpenAI 에서 만든 자체 자료형이기 때문에 응답이 깨져서 보입니다.이 경우 아래와 같이 to_dict_recursive() 함수를 이용해서 ChatGPT 의 응답을 dictionary 자료형으로 바꿀 수 있습니다.\nprint(response.to_dict_responsive())"}},"/python-fastapi-streamlit":{"title":"Python Fastapi Streamlit","data":{"python-fastapi-streamlit#Python, FastAPI, Streamlit":""}},"/python-fastapi-streamlit/python-basic":{"title":"Python Basic","data":{"파이썬-기초#파이썬 기초":"","자료형#자료형":"","클래스-선언-정의방법#클래스 선언, 정의방법":"","모듈-정의-import#모듈 정의, import":"","#...":"생각나는 대로 추가하기."}},"/python-fastapi-streamlit/streamlit-howto":{"title":"Streamlit Howto","data":{"streamlit-how-to#Streamlit How To":"","참고#참고":"streamlit.io\n공식페이지의 메인페이지 입니다. 스크롤을 내려보면 설치방법 및 다양한 예제들을 보여줍니다.\ndocs.streamlits.io\ndocs 페이지입니다.\ndocs.streamlit.io/develop/api-reference\napi-reference 페이지입니다.\ndocs.streamlits.io → 좌측 사이드바의Develop → API reference 클릭 하면 나타나는 페이지입니다.","설치#설치":"$ cd temp\r\n$ virtualenv first-demo\r\n\r\n## 프로젝트 디렉터리 이동\r\n$ cd first-demo/\r\n$ code .\r\n\r\n## 가상환경 활성화\r\n$ source ./Scripts/activate\r\n\r\n## streamlit 설치\r\n$ pip install streamlit","첫-번째-코드#첫 번째 코드":"streamlit-demo.py\nimport streamlit as st\r\n\r\nst.write(1234)\r\nst.title(\"1234\")\n실행해봅니다.\n$ streamlit run streamlit-demo.py\n실행결과는 아래와 같습니다.","두-번째-코드#두 번째 코드":"이번에는 마크다운을 출력해봅니다.streamlit-markdown.py\nimport streamlit as st\r\n\r\n\"\"\"\r\n## 제목\r\n### 부제\r\n#### 소제목\r\n\r\n- 홍길동\r\n- 고영희\r\n\"\"\"\r\n실행해봅니다.\n$ streamlit run streamlit-markdown.py\n출력결과는 아래와 같습니다. 마크다운이 잘 출력되었습니다.","세-번째-코드#세 번째 코드":"streamlit-gui-1.py\nimport streamlit as st\r\n\r\ntext = st.text_input(\"이메일을 입력해주세요\")\r\nst.write(text)\r\n\r\nagreeFlag = st.checkbox(\"개인정보 수집 동의\")\r\nif agreeFlag:\r\n    st.success(\"동의합니다.\")\r\n실행해봅니다.\n$ streamlit run streamlit-gui-1.py\n출력결과는 아래와 같습니다.","네-번째-코드#네 번째 코드":"streamlit-gui-2.py\nimport streamlit as st\r\n\r\nfood = st.selectbox(\"다이어트 때 미치는 음식\", {\"라면\", \"신라면\", \"새우깡\", \"삼겹살\", \"피자\"})\r\nst.write(f\"결과 : {food}\")\r\n실행해봅니다.\n$ streamlit run streamlit-gui-2.py\n출력결과는 아래와 같습니다.","다섯-번째-코드#다섯 번째 코드":"streamlit-gui-3.py\nimport streamlit as st\r\n\r\nfoods = st.multiselect(\"다이어트 때 미치는 음식\", {\"라면\", \"신라면\", \"새우깡\", \"삼겹살\", \"피자\"})\r\n\r\nst.write(', '.join(foods))\r\n실행해봅니다.\n$ streamlit run streamlit-gui-3.py\n출력결과","여섯-번째-코드#여섯 번째 코드":"streamlit-gui-4.py\nimport streamlit as st\r\n\r\nst.metric(label=\"MSFT\", value=\"399.12 USD\", delta=\"-5.15 USD\")\n실행해봅니다.\n$ streamlit run streamlit-gui-4.py\n출력결과는 아래와 같습니다."}},"/python-fastapi-streamlit/fastapi-howto":{"title":"Fastapi Howto","data":{"fastapi-how-to#FastAPI How To":"","참고#참고":"튜토리얼 - 사용자 가이드\nhttps://fastapi.tiangolo.com/ko/","설치#설치":"참고 : https://fastapi.tiangolo.com/ko/#_4\n$ cd temp\r\n$ virtualenv first-demo\r\n\r\n## 가상환경 활성화\r\n$ source first-demo/Scripts/activate\r\n\r\n## fastapi 설치\r\n$ pip install fastapi\r\n$ pip install \"uvicorn[standard]\"\r\n\r\n## 프로젝트 디렉터리 이동\r\n$ cd first-demo/\r\n$ code .","첫-번째-예제#첫 번째 예제":"https://fastapi.tiangolo.com/ko/#_6 의 코드를 복사후 main.py 라는 파일을 만들어서 복사한 내용을 붙여넣어서 저장\nfrom typing import Union\r\n\r\nfrom fastapi import FastAPI\r\n\r\napp = FastAPI()\r\n\r\n\r\n@app.get(\"/\")\r\ndef read_root():\r\n    return {\"Hello\": \"World\"}\r\n\r\n\r\n@app.get(\"/items/{item_id}\")\r\ndef read_item(item_id: int, q: Union[str, None] = None):\r\n    return {\"item_id\": item_id, \"q\": q}\r\n\r\n@app.get(\"/search\")\r\ndef query_item(query: str):\r\n    return {\"your query = \" + query}","실행#실행":"참고 : https://fastapi.tiangolo.com/ko/#_7\n$ uvicorn main:app --reload\n위 명령어는 아래와 같은 의미입니다.\nmain.py 라는 파일 내에 선언한 app 을 실행할 거야. 그리고 --reload 옵션을 통해 수정될때마다 재기동해줘","app#@app":"get, post, put, delete 등의 REST API 연산은 아래와 같이 @app 내에 정의된 데코레이션을 통해 정의 가능합니다.\n@app.get(\"/\")\n@app.get(\"/items/{item_id}\")\n@app.post(\"/items/{item_id}\")\n@app.put(\"/items/{item_id}\")\n@app.delete(\"/items/{item_id}\")\nPOST, PUT 연산의 차이는 아래와 같습니다.\nPOST : 항상 같은 결과값을 보장하지 않는 연산을 수행할 때\n사용자 추가, 댓글 추가 등과 같은 기존상태에서 추가되어 돌려받는 결과가 달라지는 연산들\nPUT : 항상 같은 결과값이 보장되는 멱등성 연산결과를 보장할 때\n사용자 정보 수정, 댓글 수정 등과 같이 한번의 요청에 대해 돌려받는 응답의 \"형식\"이 같을 경우 사용\n응답본문의 내용은 달라지지만 통신시 주고받는 데이터의 형식(상태코드 등)은 달라지지 않는다.","path-variable#Path Variable":"Path Variable 은 예를 들면 아래와 같이 선언 가능합니다.main.py\n# ...\r\n\r\n@app.get(\"/items/{item_id}\")\r\ndef read_item(item_id: int, q: Union[str, None] = None):\r\n    return {\"item_id\": item_id, \"q\": q}","query-parameter#Query Parameter":"Query Parameter 는 예를 들면 아래와 같이 선언 가능합니다.main.py\n# ...\r\n\r\n@app.get(\"/search\")\r\ndef query_item(query: str):\r\n    return {\"your query = \" + query}","api-문서#API 문서":"Swagger 나 Springdoc 같은 API 문서는 http://127.0.0.1:8000/docs 에 접속하면 확인 가능합니다.","eof#EOF":"저는 일반적인 개발팀 내부적으로 필요할만한 기능들을 FastAPI 와 ChatGPT 를 기반으로 제공할 수 있도록 하는 in house tool 을 만들기 위해 Fast API 를 오늘 처음 배웠는데요. 혹시라도 이 글을 읽고 계시는 분 들 중 Python 을 주력으로 사용하시려는 분들이라면 더 자세한 내용은 아래의 내용을 확인하시기 바랍니다.\n튜토리얼 - 사용자 가이드\nhttps://fastapi.tiangolo.com/ko/"}},"/references":{"title":"References","data":{"":"Referencesminiconda\nminiconda\nMiniconda → Installing Miniconda\nvirtualenv\nvirtualenv\ninstallation\nFastAPI\nFastAPI\nhttps://fastapi.tiangolo.com/ko/\n튜토리얼 - 사용자 가이드\nStreamlit\nstreamlit.io\n공식페이지의 메인페이지 입니다. 스크롤을 내려보면 설치방법 및 다양한 예제들을 보여줍니다.\ndocs.streamlits.io\ndocs 페이지입니다.\ndocs.streamlit.io/develop/api-reference\napi-reference 페이지입니다.\ndocs.streamlits.io → 좌측 사이드바의Develop → API reference 클릭 하면 나타나는 페이지입니다.\nOpenAI start\nopenai.com\nopenai.com/docs/introduction\nopenai.com/docs/quickstart?context=python\nStep 2: Set up your API key\nStep 3: Sending your first API request"}}}